import { LLMService } from './llmService.js';
import { logger, colors } from './logger.js';

/**
 * OpenRouter LLM Service
 * Connects to OpenRouter API for unified access to multiple AI models
 */
export class OpenRouterService extends LLMService {
  /**
   * Create a new OpenRouter service
   * @param {string} apiKey - The OpenRouter API key
   * @param {string} model - The model to use (default: openai/gpt-3.5-turbo)
   */
  constructor(apiKey, model = 'openai/gpt-3.5-turbo') {
    super();

    if (!apiKey) {
      throw new Error('OPENROUTER_API_KEY is required for OpenRouterService');
    }

    this.apiKey = apiKey;
    this.model = model;
    this.baseUrl = 'https://openrouter.ai/api/v1';
  }

  /**
   * Get the service name for logging
   * @returns {string}
   */
  getServiceName() {
    return 'OpenRouter';
  }

  /**
   * Convert HTML to Markdown using OpenRouter
   * @param {string} html - The HTML content to convert
   * @param {string} url - The source URL (for logging)
   * @returns {Promise<string>} - The converted Markdown content
   */
  async convertHtmlToMarkdown(html, url) {
    const serviceName = this.getServiceName();
    console.log(colors.cyan(`Using ${serviceName} service (${this.model})`));
    const totalStart = Date.now();

    await logger.info(`Starting ${serviceName} API call`, {
      url,
      htmlLength: html.length,
      model: this.model,
      timestamp: new Date().toISOString()
    });

    try {
      // Build the prompt
      const promptStart = Date.now();
      const prompt = this.buildConversionPrompt(html);
      const promptTime = Date.now() - promptStart;
      console.log(colors.dim(`Prompt prepared (${promptTime}ms, ${html.length} chars HTML)`));

      await logger.debug(`${serviceName} API request details`, {
        promptLength: prompt.length,
        htmlLength: html.length,
        truncated: html.length > 50000,
        model: this.model
      });

      // Make the API call to OpenRouter
      const apiStart = Date.now();
      const response = await fetch(`${this.baseUrl}/chat/completions`, {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${this.apiKey}`,
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          model: this.model,
          messages: [
            {
              role: 'user',
              content: prompt
            }
          ]
        })
      });

      if (!response.ok) {
        const errorText = await response.text();
        throw new Error(`OpenRouter API error (${response.status}): ${errorText}`);
      }

      const data = await response.json();
      const apiTime = Date.now() - apiStart;
      console.log(colors.success(`API call complete (${apiTime}ms)`));

      // Extract the generated text
      const parseStart = Date.now();
      const generatedText = data.choices?.[0]?.message?.content?.trim() || '';

      if (!generatedText) {
        await logger.error(`No content generated by ${serviceName}`, {
          url,
          model: this.model,
          response: JSON.stringify(data)
        });
        throw new Error(`No content generated by ${serviceName} API`);
      }

      const parseTime = Date.now() - parseStart;
      const totalTime = Date.now() - totalStart;

      console.log(colors.dim(`Response parsed (${parseTime}ms) | Total: ${totalTime}ms | Output: ${generatedText.length} chars`));

      await logger.info(`${serviceName} processing complete`, {
        url,
        totalTime,
        apiTime,
        outputLength: generatedText.length,
        model: this.model
      });

      return generatedText;

    } catch (error) {
      const totalTime = Date.now() - totalStart;

      await logger.error(`${serviceName} API error`, {
        url,
        error: error.message,
        stack: error.stack,
        totalTime,
        model: this.model
      });

      console.log(colors.error(`Error calling ${serviceName} API: ${error.message}`));
      throw error;
    }
  }
}
