import { LLMService } from './llmService.js';
import { logger, colors } from './logger.js';

/**
 * Ollama LLM Service
 * Connects directly to local Ollama instance via HTTP API
 */
export class OllamaService extends LLMService {
  /**
   * Create a new Ollama service
   * @param {string} baseUrl - The Ollama API base URL (default: http://localhost:11434)
   * @param {string} model - The Ollama model to use (default: llama2)
   */
  constructor(baseUrl = 'http://localhost:11434', model = 'llama2') {
    super();

    this.baseUrl = baseUrl.replace(/\/$/, ''); // Remove trailing slash
    this.model = model;
  }

  /**
   * Get the service name for logging
   * @returns {string}
   */
  getServiceName() {
    return 'Ollama';
  }

  /**
   * Convert HTML to Markdown using Ollama
   * @param {string} html - The HTML content to convert
   * @param {string} url - The source URL (for logging)
   * @returns {Promise<string>} - The converted Markdown content
   */
  async convertHtmlToMarkdown(html, url) {
    const serviceName = this.getServiceName();
    console.log(colors.cyan(`Using ${serviceName} service (${this.model} @ ${this.baseUrl})`));
    const totalStart = Date.now();

    await logger.info(`Starting ${serviceName} API call`, {
      url,
      htmlLength: html.length,
      model: this.model,
      baseUrl: this.baseUrl,
      timestamp: new Date().toISOString()
    });

    try {
      // Build the prompt
      const promptStart = Date.now();
      const prompt = this.buildConversionPrompt(html);
      const promptTime = Date.now() - promptStart;
      console.log(colors.dim(`Prompt prepared (${promptTime}ms, ${html.length} chars HTML)`));

      await logger.debug(`${serviceName} API request details`, {
        promptLength: prompt.length,
        htmlLength: html.length,
        truncated: html.length > 50000,
        model: this.model,
        baseUrl: this.baseUrl
      });

      // Make the API call to Ollama
      const apiStart = Date.now();
      const response = await fetch(`${this.baseUrl}/api/generate`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          model: this.model,
          prompt: prompt,
          stream: false
        })
      });

      if (!response.ok) {
        const errorText = await response.text();
        throw new Error(`Ollama API error (${response.status}): ${errorText}`);
      }

      const data = await response.json();
      const apiTime = Date.now() - apiStart;
      console.log(colors.success(`API call complete (${apiTime}ms)`));

      // Extract the generated text
      const parseStart = Date.now();
      const generatedText = data.response?.trim() || '';

      if (!generatedText) {
        await logger.error(`No content generated by ${serviceName}`, {
          url,
          model: this.model,
          response: JSON.stringify(data)
        });
        throw new Error(`No content generated by ${serviceName} API`);
      }

      const parseTime = Date.now() - parseStart;
      const totalTime = Date.now() - totalStart;

      console.log(colors.dim(`Response parsed (${parseTime}ms) | Total: ${totalTime}ms | Output: ${generatedText.length} chars`));

      await logger.info(`${serviceName} processing complete`, {
        url,
        totalTime,
        apiTime,
        outputLength: generatedText.length,
        model: this.model
      });

      return generatedText;

    } catch (error) {
      const totalTime = Date.now() - totalStart;

      await logger.error(`${serviceName} API error`, {
        url,
        error: error.message,
        stack: error.stack,
        totalTime,
        model: this.model,
        baseUrl: this.baseUrl
      });

      console.log(colors.error(`Error calling ${serviceName} API: ${error.message}`));
      throw error;
    }
  }
}
