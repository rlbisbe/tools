# ===== LLM Service Configuration =====
# Service type: 'api', 'cli', or 'mock'
# - 'api': Use Google Generative AI API directly (recommended, requires GEMINI_API_KEY)
# - 'cli': Use CLI tools like gemini-cli, kiro, or claude (legacy, requires CLI_COMMAND)
# - 'mock': Use simple HTML parser for testing (no API key or CLI tool needed)
LLM_SERVICE_TYPE=api

# ===== API Configuration (for LLM_SERVICE_TYPE=api) =====
# Get your API key from https://aistudio.google.com/app/apikey
GEMINI_API_KEY=your_gemini_api_key_here

# Gemini model to use (default: gemini-1.5-flash)
# Options: gemini-1.5-flash, gemini-1.5-pro, gemini-2.0-flash-exp
GEMINI_MODEL=gemini-1.5-flash

# ===== CLI Configuration (for LLM_SERVICE_TYPE=cli, legacy support) =====
# Choose which AI CLI tool to use: 'gemini', 'kiro', or 'claude'
CLI_TOOL_TYPE=gemini

# Command to invoke the CLI tool
# For Gemini: 'gemini' or full path to gemini executable
# For Kiro: 'kiro' or full path to kiro executable
# For Claude Code: 'claude' or full path to claude executable
CLI_COMMAND=gemini

# ===== Mock Service (legacy support) =====
# Set to 'true' to use mock service (for testing without API key or CLI tool)
# This will override LLM_SERVICE_TYPE
USE_MOCK_GEMINI=false

# Twitter API Configuration (optional - for Twitter/X URL support)
# Get your Bearer Token from https://developer.twitter.com/en/portal/dashboard
TWITTER_BEARER_TOKEN=your_twitter_bearer_token_here

# Input Configuration
OBSIDIAN_NOTES_PATH=./notes

# Processing Options
# Set to 'true' to preview results without modifying files
DRY_RUN=false
